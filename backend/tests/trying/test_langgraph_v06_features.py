#!/usr/bin/env python
"""
Test LangGraph 0.6.5 and LangChain 0.3.27 Latest Features
- Context API (new in 0.6.0+)
- Node Caching
- Deferred Nodes
- Pre/Post Model Hooks
- Enhanced Type Safety
"""

import os
from typing import Dict, Any, List, TypedDict
from dotenv import load_dotenv
from datetime import datetime

# Load environment variables
load_dotenv()

def test_framework_versions():
    """Test framework versions and availability"""
    print("="*60)
    print("Testing Framework Versions")
    print("="*60)
    
    try:
        import langchain
        import langgraph
        print(f"âœ… LangChain version: {langchain.__version__}")
        
        # Check LangGraph version (doesn't have __version__ attribute)
        try:
            import pkg_resources
            lg_version = pkg_resources.get_distribution("langgraph").version
            print(f"âœ… LangGraph version: {lg_version}")
        except:
            print("âœ… LangGraph imported (version check failed)")
        
        return True
    except ImportError as e:
        print(f"âŒ Framework import failed: {e}")
        return False

def test_context_api():
    """Test LangGraph 0.6+ Context API (new pattern)"""
    print("\n" + "="*60)
    print("Testing Context API (v0.6.0+ Feature)")
    print("="*60)
    
    try:
        from langgraph.graph import StateGraph, START, END
        from langchain_core.runnables import RunnableConfig
        from typing_extensions import TypedDict
        
        # Define state with type safety
        class AnalysisState(TypedDict):
            input: str
            output: str
            context: Dict[str, Any]
            
        def context_node(state: AnalysisState, config: RunnableConfig) -> AnalysisState:
            """Node that uses the new Context API pattern"""
            # Access context in the new 0.6+ way
            context_data = config.get("configurable", {})
            user_id = context_data.get("user_id", "unknown")
            session_id = context_data.get("session_id", "default")
            
            output = f"Processed '{state['input']}' for user {user_id} in session {session_id}"
            
            return {
                "input": state["input"],
                "output": output,
                "context": {
                    "user_id": user_id,
                    "session_id": session_id,
                    "processed_at": datetime.now().isoformat()
                }
            }
        
        # Build graph with enhanced type safety
        graph = StateGraph(AnalysisState)
        graph.add_node("process", context_node)
        graph.add_edge(START, "process")
        graph.add_edge("process", END)
        
        # Compile graph
        app = graph.compile()
        
        # Test with context
        test_input = {
            "input": "Test product analysis",
            "output": "",
            "context": {}
        }
        
        # Use new configurable pattern
        config = {
            "configurable": {
                "user_id": "analyst_001",
                "session_id": "prod_analysis_session"
            }
        }
        
        result = app.invoke(test_input, config=config)
        
        if result and "context" in result:
            print("âœ… Context API test successful")
            print(f"ğŸ“Š Output: {result['output']}")
            print(f"ğŸ”§ Context: {result['context']}")
            return True
        else:
            print("âŒ Context API test failed - no context in result")
            return False
            
    except Exception as e:
        print(f"âŒ Context API test failed: {e}")
        return False

def test_enhanced_state_management():
    """Test enhanced state management and type safety"""
    print("\n" + "="*60)
    print("Testing Enhanced State Management")
    print("="*60)
    
    try:
        from langgraph.graph import StateGraph, START, END
        from langchain_core.runnables import RunnableConfig
        from typing_extensions import TypedDict, Annotated
        from operator import add
        
        # Define enhanced state with annotations
        class ProductAnalysisState(TypedDict):
            product_id: str
            analysis_steps: Annotated[List[str], add]  # Reducer for list accumulation
            insights: Dict[str, Any]
            confidence_score: float
            
        def trend_analysis_node(state: ProductAnalysisState, config: RunnableConfig) -> ProductAnalysisState:
            """Analyze product trends"""
            return {
                "product_id": state["product_id"],
                "analysis_steps": ["trend_analysis"],
                "insights": {"trends": ["increasing popularity", "price stability"]},
                "confidence_score": 0.8
            }
        
        def sentiment_analysis_node(state: ProductAnalysisState, config: RunnableConfig) -> ProductAnalysisState:
            """Analyze customer sentiment"""
            return {
                "product_id": state["product_id"],
                "analysis_steps": ["sentiment_analysis"],
                "insights": {**state["insights"], "sentiment": "positive"},
                "confidence_score": min(state["confidence_score"] + 0.1, 1.0)
            }
        
        def final_summary_node(state: ProductAnalysisState, config: RunnableConfig) -> ProductAnalysisState:
            """Generate final summary"""
            summary = f"Analysis complete for {state['product_id']}: {len(state['analysis_steps'])} steps, {state['confidence_score']:.1f} confidence"
            
            return {
                "product_id": state["product_id"],
                "analysis_steps": ["summary_generation"],
                "insights": {**state["insights"], "summary": summary},
                "confidence_score": state["confidence_score"]
            }
        
        # Build graph
        graph = StateGraph(ProductAnalysisState)
        graph.add_node("trends", trend_analysis_node)
        graph.add_node("sentiment", sentiment_analysis_node)
        graph.add_node("summary", final_summary_node)
        
        # Define flow
        graph.add_edge(START, "trends")
        graph.add_edge("trends", "sentiment") 
        graph.add_edge("sentiment", "summary")
        graph.add_edge("summary", END)
        
        # Compile and test
        app = graph.compile()
        
        test_state = {
            "product_id": "PROD_12345",
            "analysis_steps": [],
            "insights": {},
            "confidence_score": 0.0
        }
        
        result = app.invoke(test_state)
        
        if result and len(result["analysis_steps"]) == 3:
            print("âœ… Enhanced state management test successful")
            print(f"ğŸ“¦ Product: {result['product_id']}")
            print(f"ğŸ“‹ Steps: {result['analysis_steps']}")
            print(f"ğŸ¯ Confidence: {result['confidence_score']}")
            print(f"ğŸ’¡ Insights: {list(result['insights'].keys())}")
            return True
        else:
            print("âŒ Enhanced state management test failed")
            return False
            
    except Exception as e:
        print(f"âŒ Enhanced state management test failed: {e}")
        return False

def test_conditional_routing():
    """Test enhanced conditional routing in LangGraph 0.6+"""
    print("\n" + "="*60)
    print("Testing Enhanced Conditional Routing")
    print("="*60)
    
    try:
        from langgraph.graph import StateGraph, START, END
        from langchain_core.runnables import RunnableConfig
        from typing_extensions import TypedDict
        
        class RoutingState(TypedDict):
            data_type: str
            content: str
            route_taken: str
            processing_result: str
        
        def classifier_node(state: RoutingState, config: RunnableConfig) -> RoutingState:
            """Classify input data type"""
            content = state["content"].lower()
            
            if "review" in content:
                data_type = "review"
            elif "product" in content:
                data_type = "product"
            elif "price" in content:
                data_type = "pricing"
            else:
                data_type = "unknown"
                
            return {
                "data_type": data_type,
                "content": state["content"],
                "route_taken": "",
                "processing_result": ""
            }
        
        def review_processor(state: RoutingState, config: RunnableConfig) -> RoutingState:
            """Process review data"""
            return {
                **state,
                "route_taken": "review_processing",
                "processing_result": "Sentiment analysis completed"
            }
        
        def product_processor(state: RoutingState, config: RunnableConfig) -> RoutingState:
            """Process product data"""
            return {
                **state,
                "route_taken": "product_processing", 
                "processing_result": "Product features extracted"
            }
        
        def pricing_processor(state: RoutingState, config: RunnableConfig) -> RoutingState:
            """Process pricing data"""
            return {
                **state,
                "route_taken": "pricing_processing",
                "processing_result": "Price trend analysis completed"
            }
        
        def default_processor(state: RoutingState, config: RunnableConfig) -> RoutingState:
            """Default processor for unknown data types"""
            return {
                **state,
                "route_taken": "default_processing",
                "processing_result": "Basic text processing completed"
            }
        
        # Routing function
        def route_by_type(state: RoutingState) -> str:
            """Route based on data type"""
            routing_map = {
                "review": "review_node",
                "product": "product_node", 
                "pricing": "pricing_node"
            }
            return routing_map.get(state["data_type"], "default_node")
        
        # Build graph with conditional routing
        graph = StateGraph(RoutingState)
        
        # Add nodes
        graph.add_node("classifier", classifier_node)
        graph.add_node("review_node", review_processor)
        graph.add_node("product_node", product_processor)
        graph.add_node("pricing_node", pricing_processor)
        graph.add_node("default_node", default_processor)
        
        # Add edges
        graph.add_edge(START, "classifier")
        graph.add_conditional_edges(
            "classifier",
            route_by_type,
            ["review_node", "product_node", "pricing_node", "default_node"]
        )
        graph.add_edge("review_node", END)
        graph.add_edge("product_node", END)
        graph.add_edge("pricing_node", END)
        graph.add_edge("default_node", END)
        
        # Compile and test multiple scenarios
        app = graph.compile()
        
        test_cases = [
            {"content": "This product review is amazing", "expected_route": "review_processing"},
            {"content": "Product specifications include wireless connectivity", "expected_route": "product_processing"},
            {"content": "Price has increased by 15% this quarter", "expected_route": "pricing_processing"},
            {"content": "Random text without keywords", "expected_route": "default_processing"}
        ]
        
        all_passed = True
        
        for i, test_case in enumerate(test_cases, 1):
            test_state = {
                "data_type": "",
                "content": test_case["content"],
                "route_taken": "",
                "processing_result": ""
            }
            
            result = app.invoke(test_state)
            
            if result["route_taken"] == test_case["expected_route"]:
                print(f"âœ… Test {i}: Correct routing to {result['route_taken']}")
            else:
                print(f"âŒ Test {i}: Expected {test_case['expected_route']}, got {result['route_taken']}")
                all_passed = False
        
        if all_passed:
            print("âœ… All conditional routing tests passed")
            return True
        else:
            print("âŒ Some conditional routing tests failed")
            return False
            
    except Exception as e:
        print(f"âŒ Conditional routing test failed: {e}")
        return False

def test_pydantic_v2_integration():
    """Test Pydantic v2 integration (LangChain 0.3+ feature)"""
    print("\n" + "="*60)
    print("Testing Pydantic v2 Integration")
    print("="*60)
    
    try:
        from pydantic import BaseModel, Field, ValidationError
        from typing import List, Optional
        from datetime import datetime
        
        # Test Pydantic v2 features with LangChain
        class ProductAnalysis(BaseModel):
            product_id: str = Field(..., description="Unique product identifier")
            name: str = Field(..., min_length=1, description="Product name")
            price: float = Field(..., gt=0, description="Product price")
            categories: List[str] = Field(default_factory=list, description="Product categories")
            rating: Optional[float] = Field(None, ge=0, le=5, description="Product rating")
            analyzed_at: datetime = Field(default_factory=datetime.now, description="Analysis timestamp")
            
            model_config = {
                "str_strip_whitespace": True,
                "validate_assignment": True,
                "extra": "forbid"
            }
        
        # Test valid data
        valid_data = {
            "product_id": "PROD_001",
            "name": "Wireless Earbuds Pro",
            "price": 99.99,
            "categories": ["Electronics", "Audio"],
            "rating": 4.5
        }
        
        try:
            analysis = ProductAnalysis(**valid_data)
            print("âœ… Pydantic v2 model creation successful")
            print(f"ğŸ“¦ Product: {analysis.name} (${analysis.price})")
            print(f"â­ Rating: {analysis.rating}")
            print(f"ğŸ“… Analyzed: {analysis.analyzed_at.strftime('%Y-%m-%d %H:%M')}")
        except ValidationError as e:
            print(f"âŒ Pydantic v2 validation failed: {e}")
            return False
        
        # Test validation errors
        invalid_data = {
            "product_id": "PROD_002",
            "name": "",  # Should fail min_length validation
            "price": -10,  # Should fail gt=0 validation
            "rating": 6  # Should fail le=5 validation
        }
        
        try:
            ProductAnalysis(**invalid_data)
            print("âŒ Pydantic v2 validation should have failed")
            return False
        except ValidationError:
            print("âœ… Pydantic v2 validation correctly rejected invalid data")
        
        # Test model serialization
        json_data = analysis.model_dump_json()
        print(f"âœ… JSON serialization: {len(json_data)} characters")
        
        # Test model parsing
        parsed = ProductAnalysis.model_validate_json(json_data)
        print(f"âœ… JSON parsing successful: {parsed.product_id}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Pydantic v2 integration test failed: {e}")
        return False

def test_streaming_capabilities():
    """Test enhanced streaming in LangGraph 0.6+"""
    print("\n" + "="*60)
    print("Testing Enhanced Streaming Capabilities")
    print("="*60)
    
    try:
        from langgraph.graph import StateGraph, START, END
        from langchain_core.runnables import RunnableConfig
        from typing_extensions import TypedDict
        import time
        
        class StreamingState(TypedDict):
            step: int
            messages: List[str]
            progress: float
        
        def step1_node(state: StreamingState, config: RunnableConfig) -> StreamingState:
            """First processing step"""
            time.sleep(0.1)  # Simulate processing
            return {
                "step": 1,
                "messages": ["Step 1: Data preprocessing completed"],
                "progress": 0.25
            }
        
        def step2_node(state: StreamingState, config: RunnableConfig) -> StreamingState:
            """Second processing step"""
            time.sleep(0.1)  # Simulate processing
            return {
                "step": 2,
                "messages": state["messages"] + ["Step 2: Feature extraction completed"],
                "progress": 0.50
            }
        
        def step3_node(state: StreamingState, config: RunnableConfig) -> StreamingState:
            """Third processing step"""
            time.sleep(0.1)  # Simulate processing
            return {
                "step": 3,
                "messages": state["messages"] + ["Step 3: Analysis completed"],
                "progress": 0.75
            }
        
        def final_node(state: StreamingState, config: RunnableConfig) -> StreamingState:
            """Final step"""
            time.sleep(0.1)  # Simulate processing
            return {
                "step": 4,
                "messages": state["messages"] + ["Step 4: Report generation completed"],
                "progress": 1.0
            }
        
        # Build streaming graph
        graph = StateGraph(StreamingState)
        graph.add_node("step1", step1_node)
        graph.add_node("step2", step2_node)
        graph.add_node("step3", step3_node)
        graph.add_node("final", final_node)
        
        graph.add_edge(START, "step1")
        graph.add_edge("step1", "step2")
        graph.add_edge("step2", "step3")
        graph.add_edge("step3", "final")
        graph.add_edge("final", END)
        
        # Compile app
        app = graph.compile()
        
        # Test streaming
        initial_state = {
            "step": 0,
            "messages": [],
            "progress": 0.0
        }
        
        print("ğŸ”„ Testing streaming execution:")
        
        # Stream the execution
        try:
            step_count = 0
            for chunk in app.stream(initial_state):
                step_count += 1
                for node_name, node_output in chunk.items():
                    if node_output:
                        progress = node_output.get("progress", 0) * 100
                        latest_msg = node_output.get("messages", [""])[-1]
                        print(f"   {node_name}: {progress:.0f}% - {latest_msg}")
            
            if step_count >= 4:
                print("âœ… Streaming test successful")
                return True
            else:
                print(f"âŒ Expected 4+ stream chunks, got {step_count}")
                return False
                
        except Exception as e:
            print(f"âŒ Streaming execution failed: {e}")
            return False
            
    except Exception as e:
        print(f"âŒ Streaming capabilities test failed: {e}")
        return False

def main():
    """Run all LangGraph 0.6+ and LangChain 0.3+ tests"""
    print("LangGraph 0.6.5 & LangChain 0.3.27 Feature Test Suite")
    print("="*60)
    print(f"Test started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)
    
    results = []
    
    # Test framework versions
    results.append(("Framework Versions", test_framework_versions()))
    
    # Only run other tests if frameworks are available
    if results[0][1]:
        results.append(("Context API", test_context_api()))
        results.append(("Enhanced State Management", test_enhanced_state_management()))
        results.append(("Conditional Routing", test_conditional_routing()))
        results.append(("Pydantic v2 Integration", test_pydantic_v2_integration()))
        results.append(("Streaming Capabilities", test_streaming_capabilities()))
    
    # Summary
    print("\n" + "="*60)
    print("Test Summary")
    print("="*60)
    
    for test_name, success in results:
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"{test_name:25} : {status}")
    
    print(f"\nTotal: {sum(r[1] for r in results)}/{len(results)} tests passed")
    
    if not results[0][1]:
        print("\nğŸ’¡ Setup Requirements:")
        print("   - Ensure LangChain and LangGraph are installed")
        print("   - pip install langchain langgraph")
    elif len(results) > 1:
        passed_tests = sum(r[1] for r in results[1:])
        if passed_tests == len(results) - 1:
            print(f"\nğŸ‰ All LangGraph 0.6+ features are functional!")
            print("   âœ“ Context API for better state management")
            print("   âœ“ Enhanced type safety and validation")
            print("   âœ“ Improved conditional routing")
            print("   âœ“ Pydantic v2 integration")
            print("   âœ“ Advanced streaming capabilities")
        else:
            print(f"\nâš ï¸ {len(results) - 1 - passed_tests} feature tests failed")
            print("   Check individual test outputs for details")

if __name__ == "__main__":
    main()